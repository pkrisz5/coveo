{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae11aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import psycopg2\n",
    "import numpy\n",
    "import io\n",
    "import time\n",
    "import timeit\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e723e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pandas.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c61e4e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    dbname='coveo',\n",
    "    host='',\n",
    "    user='public_loader',\n",
    "    password='',\n",
    "    application_name = 'steger loader_notebook'\n",
    ")\n",
    "C = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82e71f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'datahub_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab9bd4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_comment = 'upgrade JHD 230223'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0fd815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeLogCommit:\n",
    "    def __init__(self, task, table_name = None, commit = True, verbose=True):\n",
    "        self.table_name = table_name\n",
    "        self.task = task\n",
    "        self.verbose = verbose\n",
    "        self.commit = commit\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.t0 = datetime.datetime.now()\n",
    "        self.start = timeit.default_timer()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.took = (timeit.default_timer() - self.start)\n",
    "        if self.table_name:\n",
    "            C.execute(f\"\"\"\n",
    "INSERT INTO {schema}.merge_log\n",
    "VALUES ('{common_comment}', '{self.table_name}', '{self.task}', '{self.t0}', '{datetime.datetime.now()}');\n",
    "\"\"\")\n",
    "        if self.commit:\n",
    "            conn.commit()\n",
    "        if self.verbose:\n",
    "            t = f'on {self.table_name} ' if self.table_name else ' '\n",
    "            print(f'\\n\\033[38;5;208mCode block {self.task} {t}took:\\t{self.took:.5f} seconds\\033[0;0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd296c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35c9d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898b3039",
   "metadata": {},
   "source": [
    "Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0f96bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;5;208mCode block retrieve and clean dataset  took:\t2.93347 seconds\u001b[0;0m\n"
     ]
    }
   ],
   "source": [
    "with TimeLogCommit(task = 'retrieve and clean dataset', commit = False):\n",
    "    df = pandas.read_csv(url)\n",
    "    df.drop(columns = ['Province/State', 'Lat', 'Long'], inplace = True)\n",
    "    c = pandas.read_sql(f\"SELECT * FROM {schema}.country\", con = conn)\n",
    "\n",
    "    country_map = {\n",
    "     'Burma': 'Myanmar/Burma',\n",
    "     'Cabo Verde': 'Cape Verde',\n",
    "    # 'Congo (Brazzaville)',\n",
    "    # 'Congo (Kinshasa)',\n",
    "     \"Cote d'Ivoire\": \"Côte D’Ivoire\",\n",
    "    # 'Diamond Princess',\n",
    "    # 'Holy See',\n",
    "     'Korea, North': 'North Korea',\n",
    "     'Korea, South': 'South Korea',\n",
    "    # 'Kosovo',\n",
    "    # 'MS Zaandam',\n",
    "     'Russia': 'Russian Federation',\n",
    "     'Saint Vincent and the Grenadines': 'Saint Vincent and The Grenadines',\n",
    "     'Sao Tome and Principe': 'Sao Tomé and Príncipe',\n",
    "    # 'Summer Olympics 2020',\n",
    "    # 'Taiwan*',\n",
    "     'Tanzania':'United Republic of Tanzania',\n",
    "     'US': 'United States',\n",
    "    # 'West Bank and Gaza',\n",
    "    # 'Winter Olympics 2022'   \n",
    "    }\n",
    "    \n",
    "    cols = list(df.columns)\n",
    "    cols.remove('Country/Region')\n",
    "    cols.append('id')\n",
    "\n",
    "    X = pandas.merge(\n",
    "        left = c, right = df,\n",
    "        left_on = 'country_name', right_on = 'Country/Region',\n",
    "        how = 'inner'\n",
    "    )[cols]\n",
    "\n",
    "    dfs = pandas.melt(\n",
    "        X.groupby('id').sum().reset_index(), # in case there are more than one state, sum them up\n",
    "        id_vars = 'id', var_name = 'date', value_name = \"cases\"\n",
    "    ).rename(columns={'id': 'country_id'})\n",
    "\n",
    "    year_week = lambda ts:f\"{ts.isocalendar()[0]}_{ts.isocalendar()[1]:02d}\"\n",
    "\n",
    "    dfs['date'] = pandas.to_datetime(dfs['date'])\n",
    "    dfs['year_week'] = dfs['date'].apply(year_week)\n",
    "\n",
    "    dfs_pivot = dfs.groupby(['country_id', 'year_week'])[['cases']].max()\n",
    "    dfs_pivot['diff_cases'] = dfs_pivot['cases'].diff().astype(pandas.Int32Dtype())\n",
    "\n",
    "    dfs_pivot.reset_index(inplace=True)\n",
    "    mask = dfs_pivot['country_id'] != dfs_pivot['country_id'].shift(1)\n",
    "    dfs_pivot.loc[mask, 'diff_cases'] = dfs_pivot.loc[mask, 'cases']\n",
    "    dfs_pivot[['year', 'week']] = dfs_pivot['year_week'].str.split('_', expand=True)\n",
    "    dfs_pivot.drop(columns='year_week', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d830823",
   "metadata": {},
   "source": [
    "```python\n",
    "country_db = set(c['country_name'].unique())\n",
    "country_ds = set(df['Country/Region'].unique())\n",
    "country_ds.difference(country_db)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "777b4c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_before = pandas.read_sql(f\"select * from {schema}.jhd_covid_country_weekly\", con = conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b304191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;5;208mCode block rewrite on jhd_covid_country_weekly took:\t2.40953 seconds\u001b[0;0m\n"
     ]
    }
   ],
   "source": [
    "with TimeLogCommit(task = 'rewrite', table_name = 'jhd_covid_country_weekly'):\n",
    "    C.execute(f\"TRUNCATE {schema}.jhd_covid_country_weekly;\")\n",
    "\n",
    "    pipe = io.StringIO()\n",
    "    dfs_pivot[['country_id', 'year', 'week', 'diff_cases']].to_csv(pipe, sep = '\\t', header = False, index = False)\n",
    "    pipe.seek(0)\n",
    "    C.copy_expert(f\"COPY {schema}.jhd_covid_country_weekly FROM STDIN WITH (format csv, delimiter '\\t')\", pipe)\n",
    "    pipe.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88760a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_after = pandas.read_sql(f\"select * from {schema}.jhd_covid_country_weekly\", con = conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64299e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28779, 4), (29322, 4))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_before.shape, data_after.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b0d423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
